{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Home Work Solution**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dependancie \n",
    "import pandas as pd \n",
    "from sqlalchemy import create_engine \n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "lpep_pickup_datetime      object\n",
       "lpep_dropoff_datetime     object\n",
       "store_and_fwd_flag        object\n",
       "RatecodeID                 int64\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "ehail_fee                float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "payment_type               int64\n",
       "trip_type                  int64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the two csv files\n",
    "# Load the first 100 rows\n",
    "df1 = pd.read_csv('green_tripdata_2019-10.csv', nrows=100)\n",
    "\n",
    "\n",
    "df1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationID       int64\n",
       "Borough         object\n",
       "Zone            object\n",
       "service_zone    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('taxi_zone_lookup.csv', nrows=100)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x25a508aeb30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establish connection to DB\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"taxi_zone_lookup.csv\" (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TEXT, \n",
      "\tlpep_dropoff_datetime TEXT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define the schemas for the db\n",
    "\n",
    "#convert this to the schema for the database which postgress will recognise\n",
    "print(pd.io.sql.get_schema(df1, name=\"taxi_zone_lookup.csv\", con=engine))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"green_tripdata_2019-10.csv\" (\n",
      "\t\"LocationID\" BIGINT, \n",
      "\t\"Borough\" TEXT, \n",
      "\t\"Zone\" TEXT, \n",
      "\tservice_zone TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df2, name=\"green_tripdata_2019-10.csv\", con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to batch the Upload now \n",
    "df_iter = pd.read_csv('taxi_zone_lookup.csv', iterator = True, chunksize=100000)\n",
    "df = next(df_iter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to create the table in the database\n",
    "df.head(n=0)\n",
    "df.head(n=0).to_sql(name='taxi_zone_look_up', con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to batch the Upload now \n",
    "df_iter = pd.read_csv('taxi_zone_lookup.csv', iterator = True, chunksize=100000)\n",
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Uploaded\n",
      "29.37397074699402\n",
      "Records Uploaded\n",
      "59.164255142211914\n",
      "Records Uploaded\n",
      "94.27821946144104\n",
      "Records Uploaded\n",
      "128.35995960235596\n",
      "Records Uploaded\n",
      "163.6284737586975\n",
      "Records Uploaded\n",
      "198.78789234161377\n",
      "Records Uploaded\n",
      "301.83687448501587\n",
      "Records Uploaded\n",
      "364.44664478302\n",
      "Records Uploaded\n",
      "440.31737542152405\n",
      "Records Uploaded\n",
      "548.6215372085571\n",
      "Records Uploaded\n",
      "649.0274102687836\n",
      "Records Uploaded\n",
      "757.3488824367523\n",
      "Records Uploaded\n",
      "790.7632176876068\n",
      "Records Uploaded\n",
      "829.3238244056702\n",
      "Records Uploaded\n",
      "951.8200297355652\n",
      "Records Uploaded\n",
      "1009.8238065242767\n",
      "Records Uploaded\n",
      "1043.341697216034\n",
      "Records Uploaded\n",
      "1125.8989810943604\n",
      "Records Uploaded\n",
      "1225.0418541431427\n",
      "Records Uploaded\n",
      "1327.0640678405762\n",
      "Records Uploaded\n",
      "1424.621188402176\n",
      "Records Uploaded\n",
      "1555.0024373531342\n",
      "Records Uploaded\n",
      "1662.386967420578\n",
      "Records Uploaded\n",
      "1739.306812286377\n",
      "Records Uploaded\n",
      "1825.4224262237549\n",
      "Records Uploaded\n",
      "1893.472707748413\n",
      "Records Uploaded\n",
      "1966.7654132843018\n",
      "Records Uploaded\n",
      "2035.577776670456\n",
      "Records Uploaded\n",
      "2108.9297275543213\n",
      "Records Uploaded\n",
      "2184.2025396823883\n",
      "Records Uploaded\n",
      "2253.0446722507477\n",
      "Records Uploaded\n",
      "2321.8718597888947\n",
      "Records Uploaded\n",
      "2393.9571781158447\n",
      "Records Uploaded\n",
      "2464.7220571041107\n",
      "Records Uploaded\n",
      "2530.4585387706757\n",
      "Records Uploaded\n",
      "2598.867638349533\n",
      "Records Uploaded\n",
      "2683.1430966854095\n",
      "Records Uploaded\n",
      "2767.6630532741547\n",
      "Records Uploaded\n",
      "2843.209102869034\n",
      "Records Uploaded\n",
      "2916.3375232219696\n",
      "Records Uploaded\n",
      "2990.137535095215\n",
      "Records Uploaded\n",
      "3060.424992799759\n",
      "Records Uploaded\n",
      "3136.8318541049957\n",
      "Records Uploaded\n",
      "3205.16593170166\n",
      "Records Uploaded\n",
      "3285.212641954422\n",
      "Records Uploaded\n",
      "3353.0274629592896\n",
      "Records Uploaded\n",
      "3416.1389203071594\n",
      "Records Uploaded\n",
      "3492.4694516658783\n",
      "Records Uploaded\n",
      "3568.7178654670715\n",
      "Records Uploaded\n",
      "3635.6900820732117\n",
      "Records Uploaded\n",
      "3705.1543350219727\n",
      "Records Uploaded\n",
      "3773.3137509822845\n",
      "Records Uploaded\n",
      "3851.9142904281616\n",
      "Records Uploaded\n",
      "3921.678065299988\n",
      "Records Uploaded\n",
      "3989.5454194545746\n",
      "Records Uploaded\n",
      "4059.7340381145477\n",
      "Records Uploaded\n",
      "4130.715595006943\n",
      "Records Uploaded\n",
      "4216.282493114471\n",
      "Records Uploaded\n",
      "4286.926148414612\n",
      "Records Uploaded\n",
      "4355.765283584595\n",
      "Records Uploaded\n",
      "4434.157847881317\n",
      "Records Uploaded\n",
      "4500.774529218674\n",
      "Records Uploaded\n",
      "4564.7972683906555\n",
      "Records Uploaded\n",
      "4633.836065292358\n",
      "Records Uploaded\n",
      "4714.440757751465\n",
      "Records Uploaded\n",
      "4789.674496889114\n",
      "Records Uploaded\n",
      "4862.380978107452\n",
      "Records Uploaded\n",
      "4930.6165244579315\n",
      "Records Uploaded\n",
      "4998.4046103954315\n",
      "Records Uploaded\n",
      "5076.09468960762\n",
      "Records Uploaded\n",
      "5142.493542909622\n",
      "Records Uploaded\n",
      "5209.967447042465\n",
      "Records Uploaded\n",
      "5278.652897119522\n",
      "Records Uploaded\n",
      "5356.87616610527\n",
      "Records Uploaded\n",
      "5425.6955687999725\n",
      "Records Uploaded\n",
      "5493.536719560623\n",
      "Records Uploaded\n",
      "5562.851026296616\n",
      "Records Uploaded\n",
      "5630.12216758728\n",
      "Records Uploaded\n",
      "5698.563769340515\n",
      "Records Uploaded\n",
      "5764.612554073334\n",
      "Records Uploaded\n",
      "5830.616644859314\n",
      "Records Uploaded\n",
      "5894.376253604889\n",
      "Records Uploaded\n",
      "5964.560757160187\n",
      "Records Uploaded\n",
      "6030.275547742844\n",
      "Records Uploaded\n",
      "6097.209284067154\n",
      "Records Uploaded\n",
      "6163.782586812973\n",
      "Records Uploaded\n",
      "6228.996402978897\n",
      "Records Uploaded\n",
      "6302.978804588318\n",
      "Records Uploaded\n",
      "6370.545014381409\n",
      "Records Uploaded\n",
      "6439.30220580101\n",
      "Records Uploaded\n",
      "6507.063347578049\n",
      "Records Uploaded\n",
      "6589.236645460129\n",
      "Records Uploaded\n",
      "6654.65838432312\n",
      "Records Uploaded\n",
      "6735.910033226013\n",
      "Records Uploaded\n",
      "6803.7744772434235\n",
      "Records Uploaded\n",
      "6874.968209266663\n",
      "Records Uploaded\n",
      "6945.543958902359\n",
      "Records Uploaded\n",
      "7013.720032691956\n",
      "Records Uploaded\n",
      "7081.584247112274\n",
      "Records Uploaded\n",
      "7149.398234844208\n",
      "Records Uploaded\n",
      "7225.010338306427\n",
      "Records Uploaded\n",
      "7291.490930557251\n",
      "Records Uploaded\n",
      "7358.0998442173\n",
      "Records Uploaded\n",
      "7425.919885158539\n",
      "Records Uploaded\n",
      "7512.151206254959\n",
      "Records Uploaded\n",
      "7590.091975927353\n",
      "Records Uploaded\n",
      "7664.238151073456\n",
      "Records Uploaded\n",
      "7740.428076982498\n",
      "Records Uploaded\n",
      "7810.880612373352\n",
      "Records Uploaded\n",
      "7892.848499774933\n",
      "Records Uploaded\n",
      "7958.903176307678\n",
      "Records Uploaded\n",
      "8023.555975437164\n",
      "Records Uploaded\n",
      "8093.812132120132\n",
      "Records Uploaded\n",
      "8163.813547372818\n",
      "Records Uploaded\n",
      "8233.297586202621\n",
      "Records Uploaded\n",
      "8300.627431154251\n",
      "Records Uploaded\n",
      "8378.191716432571\n",
      "Records Uploaded\n",
      "8446.391019821167\n",
      "Records Uploaded\n",
      "8553.483840703964\n",
      "Records Uploaded\n",
      "8654.658125400543\n",
      "Records Uploaded\n",
      "8762.976743936539\n",
      "Records Uploaded\n",
      "8867.709670066833\n",
      "Records Uploaded\n",
      "8978.981757879257\n",
      "Records Uploaded\n",
      "9081.87180018425\n",
      "Records Uploaded\n",
      "9189.60984826088\n",
      "Records Uploaded\n",
      "9298.372056484222\n",
      "Records Uploaded\n",
      "9408.082969665527\n",
      "Records Uploaded\n",
      "9515.21610879898\n",
      "Records Uploaded\n",
      "9610.324092149734\n",
      "Records Uploaded\n",
      "9711.09471487999\n",
      "Records Uploaded\n",
      "9827.830709218979\n",
      "Records Uploaded\n",
      "10006.180147409439\n",
      "Records Uploaded\n",
      "10156.969440698624\n",
      "Records Uploaded\n",
      "10308.525751829147\n"
     ]
    }
   ],
   "source": [
    "#upload data to the database\n",
    "t0 = time()\n",
    "while True:\n",
    "    df.to_sql('taxi_zone_lookup', engine, if_exists='append')\n",
    "    print('Records Uploaded')\n",
    "    print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to batch the Upload now \n",
    "df_iter = pd.read_csv('green_tripdata_2019-10.csv', iterator = True, chunksize=100000)\n",
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                        float64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "lpep_dropoff_datetime    datetime64[ns]\n",
       "store_and_fwd_flag              float64\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                    float64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'], errors='coerce')\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'], errors='coerce')  \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create the schema we only need the column names and the data types associated with them. \n",
    "df.head(n=0)\n",
    "df.head(n=0).to_sql(name='green_tripdata', con = engine, if_exists='replace')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "lpep_pickup_datetime      object\n",
       "lpep_dropoff_datetime     object\n",
       "store_and_fwd_flag        object\n",
       "RatecodeID                 int64\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "ehail_fee                float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "payment_type               int64\n",
       "trip_type                float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to batch the Upload now \n",
    "df_iter = pd.read_csv('green_tripdata_2019-10.csv', iterator = True, chunksize=100000)\n",
    "df = next(df_iter)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "lpep_dropoff_datetime    datetime64[ns]\n",
       "store_and_fwd_flag               object\n",
       "RatecodeID                        int64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "passenger_count                   int64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                      int64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data types to the correct format\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'], errors='coerce')\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'], errors='coerce')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
